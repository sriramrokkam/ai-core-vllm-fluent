service:
  flush: 1
  log_level: info
  http_server: on
  http_listen: 127.0.0.1
  http_port: 2020

pipeline:
  inputs:
    # Application logs from vLLM
    - name: tail
      path: /app/logs/app.log
      tag: vllm-app
      parser: json

    # vLLM Prometheus metrics
    - name: prometheus_scrape
      host: 127.0.0.1
      port: 8000
      tag: vllm-metrics
      metrics_path: /metrics
      scrape_interval: 10s

  filters:
    # Parse nested JSON in log field
    - name: parser
      match: vllm-app
      key_name: log
      parser: json
      reserve_data: true
      preserve_key: false

    # Extract metrics from vLLM throughput messages
    - name: lua
      match: vllm-app
      script: |
        function extract_metrics(tag, timestamp, record)
          local msg = record["msg"]
          if msg and string.find(msg, "throughput") then
            -- Extract numeric values from throughput message
            local prompt_throughput = string.match(msg, "Avg prompt throughput: ([%d%.]+)")
            local gen_throughput = string.match(msg, "Avg generation throughput: ([%d%.]+)")
            local running_reqs = string.match(msg, "Running: (%d+)")
            local waiting_reqs = string.match(msg, "Waiting: (%d+)")
            local gpu_usage = string.match(msg, "GPU KV cache usage: ([%d%.]+)")
            local cache_hit_rate = string.match(msg, "Prefix cache hit rate: ([%d%.]+)")
            
            if prompt_throughput then
              record["metric_prompt_throughput"] = tonumber(prompt_throughput)
              record["metric_generation_throughput"] = tonumber(gen_throughput)
              record["metric_running_requests"] = tonumber(running_reqs)
              record["metric_waiting_requests"] = tonumber(waiting_reqs)
              record["metric_gpu_cache_usage_pct"] = tonumber(gpu_usage)
              record["metric_cache_hit_rate_pct"] = tonumber(cache_hit_rate)
              record["metric_type"] = "throughput"
            end
          end
          return 2, timestamp, record
        end
      call: extract_metrics

    # Add metadata to application logs
    - name: record_modifier
      match: vllm-app
      record:
        type: log
        source: vllm-application
        environment: ${ENVIRONMENT:-production}
        category: application
        ai_core_deployment: "true"
        deployment_id: ${DEPLOYMENT_ID}
        model_name: ${MODEL_NAME}
        resource_group: default
        platform: kubernetes
        log_source: vllm-fluent-bit
        service: vllm-inference
        deployment_type: ai-core-serving

    # Process metrics: Add metadata and structure for Cloud Logging
    - name: record_modifier
      match: vllm-metrics
      record:
        type: metric
        source: vllm-prometheus
        environment: ${ENVIRONMENT:-production}
        service: vllm
        category: metrics
        ai_core_deployment: "true"
        deployment_id: ${DEPLOYMENT_ID}
        model_name: ${MODEL_NAME}
        resource_group: default

    # Add timestamp and structure for Cloud Logging metrics
    - name: lua
      match: vllm-metrics
      script: |
        function process_metrics(tag, timestamp, record)
            -- Add timestamp in ISO8601 format
            record["timestamp"] = os.date("!%Y-%m-%dT%H:%M:%S.000Z", timestamp)
            record["metric_timestamp"] = timestamp
            
            -- Extract and organize vLLM metrics
            local metrics = {}
            for key, value in pairs(record) do
                if string.match(key, "^vllm_") then
                    metrics[key] = value
                    record[key] = nil  -- Remove from root
                end
            end
            
            -- Add structured metrics
            if next(metrics) ~= nil then
                record["metrics"] = metrics
            end
            
            return 1, timestamp, record
        end
      call: process_metrics

  outputs:
    # Application logs output - HTTP with JSON format
    - name: http
      match: vllm-app
      host: ${OPENSEARCH_HOST}
      port: 443
      http_user: ${OPENSEARCH_USER}
      http_passwd: ${OPENSEARCH_PASSWORD}
      tls: on
      tls.verify: off
      format: json
      json_date_key: timestamp
      json_date_format: iso8601
      http_method: PUT
      uri: /
      compress: gzip

    # Metrics output - OpenSearch with dedicated index
    - name: opensearch
      match: vllm-metrics
      host: ${OPENSEARCH_HOST}
      port: 443
      http_user: ${OPENSEARCH_USER}
      http_passwd: ${OPENSEARCH_PASSWORD}
      index: metrics-vllm
      tls: on
      tls.verify: off
      suppress_type_name: on
